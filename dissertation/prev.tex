\chapter{Previous Work}
\label{ch:prev}
\section{Sequential Circuit Verification based on Unrolling}
The most significant difference of sequential circuits from combinational circuits is 
that the outputs of the circuit depend not only 
on the primary inputs, but also on current state. 
The behavioral difference reflect on the structual design of circuits and result in 
the existance of memory components such as latches and flip-flops.
In order to test certain properties on some signals accross multiple clock-cycles,
the most straightforward method is to propogate those signals throughout 
all clock-cycles. Moreover, for formal verification, all signals on all paths from the circuit
need to be propogated through multiple clock-cycles.
This indicates a time-to-space conversion, where 
a cut is set on the latches/flip-flops and the combinational part of circuit
is copied over several time-frames then connected together.
The procedure is called {\it unrolling} of sequential circuit, as 
Figure \ref{fig:unrolling} shows.

% fig:unrolling

Unrolling provides a way to transform a sequential circuit to combinational 
circuit. Therefore,  methods which can be applied to combinational circuit 
verification is also suitable for unrolled sequential circuits. The canonical 
graphical representation of the combinational circuit after unrolling is also 
the canonical representation of the original sequential circuit. For the sequential 
equivlance checking problem, we can also unroll the circuit to be verified and 
specification to combinational ones, then perform combinational equivlance checking
techniques. In the following part we review research and techniques which 
can be applied to unrolled sequential circuits.

\subsection{Canonical Decision Diagrams}
Canonical representations of Boolean functions have been the subject
of extensive investigation for logic synthesis and design
verification. The Reduced Ordered Binary Decision Diagram (ROBBD)
\cite{BRYA86} was the first significant contribution in this area. 
Efficient implementation of ROBDDs as a software package \cite{brace}
allowed for efficient formal verification of combinational and
sequential circuits.  ROBDDs represent a Boolean function as an
implicit set of points on a canonical directed acyclic graph
(DAG). Manipulation of Boolean functions can then be carried out as
composition operations on their respective DAGs.  The decomposition
principle behind BDDs is one of Shannon's expansion, i.e.
\begin{equation}
f(x, y, \dots) = x f_x + x' f_{x'}
\end{equation}

where $f_x = f(x = 1)$ and $f_{x'} = f(x = 0)$ denote the positive and
negative co-factors of $f$ w.r.t. $x$, respectively. Motivated by the
success of BDDs,  variants of the Shannon's decomposition principle
(Davio, Reed-Muller, etc.) were explored to develop other functional
decision diagrams. For example, the AND-OR-NOT logic based Shannon's
expansion is transformed into an AND-XOR logic based decomposition,
termed as the Davio's decomposition:

\begin{eqnarray}
f(x, y, \dots) &=& x f_x + x' f_{x'}\\
& = & x f_x \oplus x' f_{x'}\\
& = & x f_x \oplus (1 \oplus x) f_{x'}\\
& = & f_{x'} \oplus x (f_x \oplus f_{x'})
\end{eqnarray}


Decision diagrams based on such decompositions include FDDs
\cite{okfdd}, ADDs \cite{add}, MTBDDs \cite{mtbdd}, and their hybrid 
edge-valued counterparts, HDDs \cite{hdd} and EVBDDs \cite{evbdd}. 
While these are referred to as {\it Word-Level Decision Diagrams}
\cite{WLS}, the decomposition is still point-wise, binary, 
w.r.t. each Boolean variable. These representations do not
serve the purpose of word-level abstraction from bit-level
representations. 

Binary Moment Diagrams (BMDs) \cite{bmd}, and its derivatives K*BMDs
\cite{kbmd} and *PHDDs \cite{phdd}, depart from the Boolean
decomposition and perform the decomposition of a {\it linear} function
based on its two moments. BMDs provide a compact representation for
integer arithmetic circuits such as multipliers and squarers. However,
these are inapplicable to word-level abstraction of modulo-arithmetic
circuits over Galois fields. 


Taylor Expansion Diagrams (TEDs) \cite{ted_tcomp} are a
word-level canonical representation of a {\it polynomial expression},
based on the Taylor's series expansion of a polynomial. However, they do
not represent a {\it polynomial function} canonically. For example,
$f_1 = 0$ and $f_2 = 2x^2 - 2x \pmod{ 4}$ are two different polynomial
representations of the zero function over $\Z_4$; but they are
symbolically different polynomials and they have non-isomorphic TED
DAGs.  While \cite{namrata:phd}  and \cite{alizadeh:tcad2010} provide 
canonical representations of polynomial functions, they do so over
finite integer rings $\Z_{2^k}$ and not over Galois fields $\Fkk$.


MODDs \cite{modd} \cite{modd_tcomp} are a DAG representation of the
characteristic function of a circuit over Galois fields $\Fkk$. MODDs
come very close to satisfying our requirements as a canonical
word-level representation that can be employed over Galois fields, as
it essentially interpolates a polynomial from the characteristic 
function. However, MODDs do not scale very well for large circuits ---
this is because every node in the DAG can have up to $k$ children and
the normalization operations are very complicated for MODDs. They also
suffer from the size explosion problem during intermediate
computations. They are known to be infeasible in representing
functions over $32$-bit operand words. 

% TODO find good shifts on this paragraph

DD-based model checking is very efficient as long as the DDs of sequential 
circuit can be setup. The existence of violating states in constructed DDs 
immediately deduces the violation of property. However, when the design gets
larger and larger, the time and space cost of building and storing the diagram 
increases rapidly. In our experiment of verifying a $k$-bit arithmetic circuit 
using ZDDs, when $k$ is larger than 100, the construction of ZDDs occupies 
over $99\%$ runtime of the whole procedure.
\subsection{Combinational Equivalence Checking Techniques}
The verification problem addressed in this dissertation is a
manifestation of the combinational equivalence checking (CEC) problem,
where the specification (polynomial) and  the implementation (circuit)
are custom-designed, structurally very dissimilar circuits. To make
use of contemporary gate-level CEC tools, we can take the 
specification circuit (``golden model'') and check its equivalence
against the implementation circuit. Canonical decision diagrams (BDDs
\cite{BRYA86} and their word-level variants \cite{WLS}),
And-Invert-Graph (AIG) based reductions \cite{AIG:2002}
\cite{alanmi:cec:iccad2006}, circuit-SAT solvers \cite{csat}, etc.,
are among the many techniques that can be employed for this CEC.  
When one circuit is synthesized from the 
other, this problem can be efficiently solved using AIG-based
reductions (e.g. the ABC tool \cite{abc}) and circuit-SAT solvers
(e.g., CSAT \cite{csat}). 
Synthesized circuits generally contain many
sub-circuit equivalences which AIG and CSAT based tools can identify
and exploit for verification. However, when the circuits are
functionally equivalent but structurally very dissimilar (e.g.,
Mastrovito \cite{mastro:1989} versus Montgomery implementations
\cite{acar:1998} of Galois field circuits), none of the 
  contemporary techniques, including ABC and CSAT, offer a practical
  solution. Automatic formal verification of large {\it
    custom-designed modulo-arithmetic circuits} largely remains
  unsolved today.    

This verification problem is very hard for SAT solvers and also for
quantifier-free bit-vector (QF-BV) theory based SMT-solvers, due to
the large circuit size, and the presence of AND-XOR-SHIFT structures. 
Similarly, the Cryptol tool-set \cite{Cryptol:fmcad09} also employs
AIG-based reductions (SAT-sweeping) and SAT/SMT-solvers for
verification of crypto-protocols. For applications where
AIGs/SAT/SMT-techniques fail, the {\it Cryptol} tool-set also does not
deliver. As shown in \cite{lv:phd}, {\it none of BDDs, SAT, SMT
  solvers, nor the  ABC tool can prove design equivalence beyond
  $16$-bit circuits.}

%TODO add what I wrote for rolf & cunxi (refer to the new paper)%%%%%%%
In \cite{ciesielski:flow}, the authors present a method
for verification of integer multipliers using a data-flow
approach. This work abstracts a polynomial function
of the given multiplier and then solves the network flow problem 
using algebraic techniques. However, the abstraction is 
solely bit-level, and is thus not applicable to deriving 
a word-level representation of a given design.

\section{Word-level Techniques applied to Sequential Circuit Synthesis and Validation}
% TODO Talk bit-level and bit-blast

Other attempts to derive high-level representations of functions,
along with associated decision procedures, can be found in
the rich domain of formal model checking \cite{BHEL96} \cite{SMV},
theorem proving \cite{arditi:bmd}, bit-vector SMT-solvers
\cite{boolector} \cite{cvc3} \cite{z3} \cite{bitvector98}, automated
decision procedures for Presburger arithmetic \cite{presburger}
\cite{bultan:mixed_verification}, algebraic manipulation techniques 
\cite{devadas:algebraic_manipulation_iccd91}, or the ones based on
term re-writing \cite{AST}, etc. % TODO expand term rewriting

Polynomial, integer and other non-linear representations have also
been researched: Difference Decision Diagrams (DDDs) \cite{ddd-csl99} \cite{ddd-mt-98}, interval
diagrams \cite{interval_dd}, interval analysis using polynomials
\cite{polynomial_sanchez99}, etc. Most of these have found 
application in constraint satisfaction for simulation-based
validation:  \cite{Ritter99} \cite{hsat} \cite{lpsat}
\cite{brinkmann:asp-dac} \cite{Huang:tcad01} \cite{bitvector98}. Among
these, \cite{brinkmann:asp-dac} \cite{Huang:tcad01} \cite{bitvector98}
have been used to {\it solve} integer modular arithmetic on linear
expressions - a different application from {\it representing}
finite field modulo-arithmetic on polynomials in a canonical form.   

% TODO Uninterpreted function abstraction


\section{Abstraction Refinement Techniques}

\section{Verification using Algebraic Geometry}

\section{Concluding Remarks}
For the problem of word-level, canonical, polynomial abstractions
of Galois field arithmetic circuits over $\Fkk$, previous related work 
is either inapplicable or only applicable to circuits no larger than
$32$-bits in size.
Therefore, we propose a {\it symbolic approach} to
polynomial interpolation from a circuit using the Gr\"obner basis
computation. However, the complexity of a \Grobner basis computation is 
prohibitively expensive; thus, we propose further improvements to this 
approach by deriving a smaller subset of computations based on a \Grobner
basis analysis. These improvements allow for abstractions of 
flattened Galois field circuits up to $571$-bits, which is the largest NIST 
standard for ECC, or up to $1024$-bits when a hierarchy is given. 
Furthermore, we propose applications of this 
approach to allow for formal verification of flattened Galois field circuits up to 
$1024$-bits, where current techniques are only applicable for circuits up 
to $163$-bits.