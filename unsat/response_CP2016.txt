Review 1:
-- Originality issue?
Our heuristics are original, and proved to be effective by our experiments.

Review 2:
-- Any kind of theoretical guarantees?
No. This is a hard theoretical problem in algebra, because a redundant polynomial can always be written as combination of necessary polynomials, while the procedure of computing a Groebner basis does not guarantee that we can deduce all polynomial dependences in the original set. The GB computation procedure can be controlled by both monomial order and strategy to pick critical s-poly pairs, which is infeasible for exhaustive method.
--  In your experiments the GB-core algorithm runs only once and the syzygy heuristic does not provide further improvements?
Although syzygy heuristic gather extra information from the GB computation, it is still not sufficient to derive all polynomial dependencies.
-- It would be interesting to see how using the syzygy heuristic compares to re-running GB-core?
Syzygy heuristic collects extra information from GB-core algorithm, so the number of rows of syzygy matrix will be much greater than the size of original polynomial set. Since it requires a full GB computation on each column of syzygy matrix, it will take too much time. For example, if we directly apply syzygy heuristic on aim-100 benchmark (79 polynomials), there are 426 rows in syzygy matrix, it is too large such that GB computation for a single column takes hours. So we use syzygy heuristic as complementation to re-running GB-core.

Review 3:
-- The paper addresses the problem of finding small unsatisfiable cores in the context of Boolean formulas presented in XNF? 
Not exactly. Both Groebner basis and unsatisfiable cores are concepts not limited to XNF,  so our approach can be applied to any decision problem formalized by polynomials over any field.
-- Benchmarks must have been translated in the opposite direction too, for use by picoMUS?
The size of MUS for benchmarks not translated from CNF is not obtained by using picoMUS. Instead, we first get a smaller core using our approach, then reduce it to minimal using exhaustive deletion-based techniques.
-- The result for GB-core without the post-processing?
We have the data and will be happy to share with the PC.
-- The result for subset-3 must be wrong, as it suggests the proposed method finds a core that is smaller than the optimal result?
No, the smaller core obtained by our approach is not a subset of the core from picoMUS. Actually we obtained a different minimal core using another MUS extractor (HaifaMUC).
-- Consider publishing all benchmarks used, including those that have been modified by adding redundant clauses. I assume StarExec is the right venue for this?
We would love to share our benchmarks and tool with the PC and the public.
-- Page 14, mid: "translation to CNF" -> "translation from CNF"?
We accept this suggestion.
-- (Important) Page 14 (mid) suggests that any scalability issues stem from translation to/from CNF, but in [12] those issues must have been overcome?
Reference [12] does not overcome the scalability issue for GB computation. In that paper, the author divided the whole set of clauses into lots of small subsets, and GB computation is operated on small sets. In our case, partitioning is not helpful for identifying smaller cores because UNSAT problem is related to a global property rather than local ones.

Review 4:
-- Is the refutation tree really helpful in the construction? Is it used for storing the computed polynomials in a more efficient way?
The refutation tree is a structure helpful in illustrating the resolution-style refutation when running the Buchberger's algorithm, as well as introducing concepts such as refutation distance and frequency of occurence. We do not use a tree-like data structure to actually storing the data. In Algorithm 2, data set D is necessary, while the construction of refutation tree T is optional and it has similar cost with extracting distance and frequency from D.
-- What is the criterion used to stop the refinement procedure (besides considering the size of the unsat core computed by another tool)?
We stop the refinement when the size of core do not decrease after more GB-core iterations are taken. It is a fixpoint detection mechanism that not rely on the MUS we learn in advance.
-- How do the execution times compare with those of picoMUS?
As the GB computation is hard and our tool is implemented through Singular which is a universal symbolic computing system that not well specialized,  the runtime is much larger than conventional tools -- their runtimes are usually less than 0.1 sec.
-- Is picoMUS the only solver to compare with? Why?
No,  we also compare the results from MUSer2 and HaifaMUC and they show identical results for most of our benchmarks. For several benchmarks (subset1~3, phole4) they give different solutions, the results from picoMUS are usually the same or a subset of the output from our tool (for subset3 our result is better than all other ones). We choose these 3 solvers because they have best performance on SAT 2011 competition (ranking 1,2,4,5 on number of solved instances and 1,2,3,5 on average CPU time for solving single instance),  which is the latest SAT competition with a MUS track.
(word count: 865)
